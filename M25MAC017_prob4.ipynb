{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sports vs Politics Text Classifier\n",
        "Label Convention: 1 = Sports, 0 = Politics\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, classification_report, confusion_matrix)\n",
        "import pickle\n",
        "import warnings\n",
        "import os\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SPORTS VS POLITICS TEXT CLASSIFIER\")\n",
        "print(\"Label Convention: 1 = Sports, 0 = Politics\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def create_data_files_from_dataframes(sports_df, politics_df, output_dir=\"data\"):\n",
        "    \"\"\"\n",
        "    Create sports.txt and politics.txt from DataFrames\n",
        "\n",
        "    Args:\n",
        "        sports_df: DataFrame with 'content' column containing sports articles\n",
        "        politics_df: DataFrame with 'content' column containing politics articles\n",
        "        output_dir: Directory to save files (default: \"data\")\n",
        "\n",
        "    Example:\n",
        "        sports_df = pd.DataFrame({'content': ['article 1', 'article 2']})\n",
        "        politics_df = pd.DataFrame({'content': ['article 1', 'article 2']})\n",
        "        create_data_files_from_dataframes(sports_df, politics_df)\n",
        "    \"\"\"\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Extract texts\n",
        "    sports_texts = sports_df[\"content\"].tolist()\n",
        "    politics_texts = politics_df[\"content\"].tolist()\n",
        "\n",
        "    # Write sports file\n",
        "    sports_file = os.path.join(output_dir, \"sports.txt\")\n",
        "    with open(sports_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for article in sports_texts:\n",
        "            # Replace newlines with spaces, write one article per line\n",
        "            f.write(article.replace(\"\\n\", \" \") + \"\\n\")\n",
        "\n",
        "    print(f\"✓ Created {sports_file} with {len(sports_texts)} articles\")\n",
        "\n",
        "    # Write politics file\n",
        "    politics_file = os.path.join(output_dir, \"politics.txt\")\n",
        "    with open(politics_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for article in politics_texts:\n",
        "            # Replace newlines with spaces, write one article per line\n",
        "            f.write(article.replace(\"\\n\", \" \") + \"\\n\")\n",
        "\n",
        "    print(f\"✓ Created {politics_file} with {len(politics_texts)} articles\")\n",
        "    print(f\"\\n Files created successfully in '{output_dir}/' directory\")\n",
        "\n",
        "\n",
        "def create_sample_data_files():\n",
        "    \"\"\"\n",
        "    Create sample data files for testing\n",
        "    Call this if you don't have DataFrames ready\n",
        "    \"\"\"\n",
        "\n",
        "    # Sample sports articles\n",
        "    sports_articles = [\n",
        "        \"Manchester United defeated Liverpool 2-1 in a thrilling Premier League match at Old Trafford.\",\n",
        "        \"The Olympic Games opening ceremony showcased spectacular performances from athletes worldwide.\",\n",
        "        \"Tennis star won the Grand Slam tournament after a five-set battle on center court.\",\n",
        "        \"Basketball team secured championship victory with last-second three-pointer in overtime.\",\n",
        "        \"Formula One driver breaks track record in qualifying session for upcoming Grand Prix.\",\n",
        "        \"Cricket World Cup final draws massive global audience as teams compete for trophy.\",\n",
        "        \"NFL quarterback throws record-breaking touchdown passes in playoff game victory.\",\n",
        "        \"Soccer fans celebrate as national team advances to tournament semifinals with penalty shootout win.\",\n",
        "        \"Swimmer sets new world record in Olympic trials breaking previous mark by two seconds.\",\n",
        "        \"Golf tournament leader maintains strong position after third round at Augusta National.\",\n",
        "        \"Boxing champion successfully defends title with unanimous decision victory in title fight.\",\n",
        "        \"Hockey team wins Stanley Cup after intense seven-game series against rivals.\",\n",
        "        \"Marathon runner finishes race in record time despite challenging weather conditions.\",\n",
        "        \"Baseball team clinches division title with walk-off home run in bottom of ninth inning.\",\n",
        "        \"Rugby match features incredible try-scoring performance from breakout star player.\",\n",
        "        \"Cycling champion wins stage race after grueling mountain climb in Tour de France.\",\n",
        "        \"Volleyball team earns gold medal at international championship with straight-set victory.\",\n",
        "        \"Figure skating competition showcases breathtaking performances from talented athletes worldwide.\",\n",
        "        \"Wrestling championship crowns new champion after dramatic final match performance.\",\n",
        "        \"Track and field athlete breaks long-standing record in 100-meter sprint event.\",\n",
        "        \"The football striker scored hat-trick in crucial derby match helping team maintain top position.\",\n",
        "        \"Basketball playoffs feature intense competition with multiple overtime games thrilling fans.\",\n",
        "        \"Tennis tournament reaches exciting conclusion with underdog defeating top seed in final.\",\n",
        "        \"Hockey goalie makes incredible saves throughout game leading team to shutout victory.\",\n",
        "        \"Baseball pitcher throws perfect game striking out fifteen batters in historic performance.\",\n",
        "        \"Soccer team wins continental championship defeating rivals in penalty shootout after final.\",\n",
        "        \"Olympic sprinter wins gold medal breaking championship record in 200-meter race.\",\n",
        "        \"Golf major championship features dramatic finish with playoff deciding winner on final hole.\",\n",
        "        \"Swimming relay team sets world record winning gold medal at international competition.\",\n",
        "        \"Boxing match ends in knockout victory as challenger defeats champion in stunning upset.\",\n",
        "    ]\n",
        "\n",
        "    # Sample politics articles\n",
        "    politics_articles = [\n",
        "        \"Prime Minister announces new economic policy aimed at reducing unemployment and inflation rates.\",\n",
        "        \"Senate votes on controversial healthcare reform bill after weeks of intense debate.\",\n",
        "        \"President delivers State of the Union address outlining administration priorities for coming year.\",\n",
        "        \"Parliament debates climate change legislation with cross-party support for environmental measures.\",\n",
        "        \"Election results show surprising victory for opposition party in key swing districts.\",\n",
        "        \"Congressional hearing examines government spending and budget allocation priorities.\",\n",
        "        \"Political leaders meet for summit to discuss international trade agreements and tariffs.\",\n",
        "        \"Supreme Court issues landmark ruling on constitutional rights impacting federal law.\",\n",
        "        \"Governor signs executive order addressing state infrastructure and transportation funding.\",\n",
        "        \"Political campaign announces policy platform focused on education and healthcare reform.\",\n",
        "        \"Lawmakers negotiate bipartisan compromise on immigration reform legislation in committee.\",\n",
        "        \"Presidential candidate leads polls ahead of primary elections in crucial battleground states.\",\n",
        "        \"Cabinet reshuffle announced following resignation of senior government minister official.\",\n",
        "        \"International diplomacy efforts intensify as nations negotiate peace treaty and sanctions.\",\n",
        "        \"Political party convention nominates candidate for upcoming national election campaign.\",\n",
        "        \"Congressional committee investigates allegations of corruption in government contracting process.\",\n",
        "        \"United Nations assembly votes on resolution addressing humanitarian crisis and aid distribution.\",\n",
        "        \"State legislature passes controversial bill on voting rights and election security measures.\",\n",
        "        \"Political analyst predicts electoral outcomes based on recent polling data and trends.\",\n",
        "        \"Government announces stimulus package to support economy during financial crisis period.\",\n",
        "        \"Parliamentary session discusses proposed constitutional amendments affecting citizen rights.\",\n",
        "        \"Foreign minister announces new diplomatic initiative to strengthen international relations.\",\n",
        "        \"Senate majority leader calls for bipartisan cooperation on infrastructure spending bill.\",\n",
        "        \"Political protest draws thousands demanding policy changes on social justice issues.\",\n",
        "        \"Presidential administration unveils comprehensive plan to address national security concerns.\",\n",
        "        \"Congress debates military spending authorization bill for defense budget allocation.\",\n",
        "        \"Governor vetoes legislation citing concerns about fiscal impact on state budget.\",\n",
        "        \"International summit addresses global trade disputes with negotiations between powers.\",\n",
        "        \"Political scandal investigation leads to resignation of cabinet official amid pressure.\",\n",
        "        \"Legislative committee holds hearing on environmental regulations affecting emissions.\",\n",
        "    ]\n",
        "\n",
        "    # Create DataFrames\n",
        "    sports_df = pd.DataFrame({'content': sports_articles})\n",
        "    politics_df = pd.DataFrame({'content': politics_articles})\n",
        "\n",
        "    # Create files\n",
        "    create_data_files_from_dataframes(sports_df, politics_df)\n",
        "\n",
        "    return sports_df, politics_df\n",
        "\n",
        "\n",
        "# STEP 1: LOAD DATA FROM FILES\n",
        "\n",
        "def load_data_from_files(sports_file=\"data/sports.txt\", politics_file=\"data/politics.txt\"):\n",
        "    \"\"\"\n",
        "    Load data from text files\n",
        "    Label convention: 1 = Sports, 0 = Politics\n",
        "    \"\"\"\n",
        "    print(\"\\n[1/7] LOADING DATA FROM FILES\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    document_lines = []\n",
        "    labels = []\n",
        "\n",
        "    # Load Sports (label = 1)\n",
        "    if os.path.exists(sports_file):\n",
        "        with open(sports_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    document_lines.append(line)\n",
        "                    labels.append(1)\n",
        "        print(f\" Loaded sports data from {sports_file}\")\n",
        "    else:\n",
        "        print(f\" Warning: {sports_file} not found\")\n",
        "\n",
        "    # Load Politics (label = 0)\n",
        "    if os.path.exists(politics_file):\n",
        "        with open(politics_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    document_lines.append(line)\n",
        "                    labels.append(0)\n",
        "        print(f\" Loaded politics data from {politics_file}\")\n",
        "    else:\n",
        "        print(f\" Warning: {politics_file} not found\")\n",
        "\n",
        "    print(f\"\\n Dataset Summary:\")\n",
        "    print(f\"   Total documents: {len(document_lines)}\")\n",
        "    print(f\"   Sports (label=1): {labels.count(1)}\")\n",
        "    print(f\"   Politics (label=0): {labels.count(0)}\")\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        'text': document_lines,\n",
        "        'label': labels\n",
        "    })\n",
        "\n",
        "    # Shuffle\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# STEP 2: EXPLORATORY DATA ANALYSIS\n",
        "\n",
        "\n",
        "def perform_eda(df):\n",
        "    \"\"\"Perform exploratory data analysis\"\"\"\n",
        "    print(\"\\n[2/7] EXPLORATORY DATA ANALYSIS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Add text statistics\n",
        "    df['text_length'] = df['text'].str.len()\n",
        "    df['word_count'] = df['text'].str.split().str.len()\n",
        "\n",
        "    # Statistics by category\n",
        "    print(\"\\n Text Statistics by Category:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for label, name in [(1, \"Sports\"), (0, \"Politics\")]:\n",
        "        subset = df[df['label'] == label]\n",
        "        print(f\"\\n{name} (label={label}):\")\n",
        "        print(f\"  Count: {len(subset)}\")\n",
        "        print(f\"  Avg length: {subset['text_length'].mean():.1f} characters\")\n",
        "        print(f\"  Avg words: {subset['word_count'].mean():.1f} words\")\n",
        "        print(f\"  Min words: {subset['word_count'].min()}\")\n",
        "        print(f\"  Max words: {subset['word_count'].max()}\")\n",
        "\n",
        "    # Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Class distribution\n",
        "    ax1 = axes[0, 0]\n",
        "    label_counts = df['label'].value_counts().sort_index()\n",
        "    colors = ['#FF6B6B', '#4ECDC4']\n",
        "    bars = ax1.bar(['Politics (0)', 'Sports (1)'],\n",
        "                    [label_counts[0], label_counts[1]],\n",
        "                    color=colors, edgecolor='black')\n",
        "    ax1.set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
        "    ax1.set_ylabel('Number of Documents')\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{int(height)}',\n",
        "                ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    # Text length distribution\n",
        "    ax2 = axes[0, 1]\n",
        "    for label, name, color in [(1, 'Sports', '#4ECDC4'), (0, 'Politics', '#FF6B6B')]:\n",
        "        data = df[df['label'] == label]['text_length']\n",
        "        ax2.hist(data, alpha=0.6, label=name, bins=20, color=color, edgecolor='black')\n",
        "    ax2.set_title('Text Length Distribution', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Text Length (characters)')\n",
        "    ax2.set_ylabel('Frequency')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Word count distribution\n",
        "    ax3 = axes[1, 0]\n",
        "    for label, name, color in [(1, 'Sports', '#4ECDC4'), (0, 'Politics', '#FF6B6B')]:\n",
        "        data = df[df['label'] == label]['word_count']\n",
        "        ax3.hist(data, alpha=0.6, label=name, bins=20, color=color, edgecolor='black')\n",
        "    ax3.set_title('Word Count Distribution', fontsize=14, fontweight='bold')\n",
        "    ax3.set_xlabel('Number of Words')\n",
        "    ax3.set_ylabel('Frequency')\n",
        "    ax3.legend()\n",
        "\n",
        "    # Box plot\n",
        "    ax4 = axes[1, 1]\n",
        "    box_data = [df[df['label'] == 0]['word_count'], df[df['label'] == 1]['word_count']]\n",
        "    bp = ax4.boxplot(box_data, labels=['Politics (0)', 'Sports (1)'],\n",
        "                     patch_artist=True)\n",
        "    for patch, color in zip(bp['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "    ax4.set_title('Word Count by Category', fontsize=14, fontweight='bold')\n",
        "    ax4.set_ylabel('Word Count')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save plot\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    plt.savefig('results/eda_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\n✓ Saved visualization: results/eda_analysis.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Top words analysis\n",
        "    print(\"\\n Top Words by Category:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    stop_words = {'the', 'and', 'for', 'with', 'from', 'that', 'this',\n",
        "                 'was', 'were', 'are', 'has', 'had', 'but', 'not', 'after',\n",
        "                 'before', 'when', 'where', 'who', 'what', 'which', 'how'}\n",
        "\n",
        "    for label, name in [(1, \"Sports\"), (0, \"Politics\")]:\n",
        "        text = ' '.join(df[df['label'] == label]['text'].values)\n",
        "        words = re.findall(r'\\b[a-z]{3,}\\b', text.lower())\n",
        "        words = [w for w in words if w not in stop_words]\n",
        "\n",
        "        word_freq = Counter(words).most_common(20)\n",
        "\n",
        "        print(f\"\\n{name} (label={label}):\")\n",
        "        for word, freq in word_freq[:10]:\n",
        "            print(f\"  {word:.<20} {freq:>4}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# STEP 3: TRAIN-TEST SPLIT\n",
        "\n",
        "\n",
        "def prepare_train_test_split(df):\n",
        "    \"\"\"Split data into train and test sets\"\"\"\n",
        "    print(\"\\n[3/7] PREPARING TRAIN-TEST SPLIT\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    X = df['text'].values\n",
        "    y = df['label'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(X_train)} documents\")\n",
        "    print(f\"  Sports (1): {sum(y_train == 1)}\")\n",
        "    print(f\"  Politics (0): {sum(y_train == 0)}\")\n",
        "\n",
        "    print(f\"\\nTest set: {len(X_test)} documents\")\n",
        "    print(f\"  Sports (1): {sum(y_test == 1)}\")\n",
        "    print(f\"  Politics (0): {sum(y_test == 0)}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# STEP 4: TRAIN MULTIPLE MODELS\n",
        "\n",
        "\n",
        "def train_all_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Train and evaluate multiple models\"\"\"\n",
        "    print(\"\\n[4/7] TRAINING MULTIPLE MODELS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Model configurations\n",
        "    configs = [\n",
        "        ('bow', (1, 1), 'Bag of Words', 'nb', 'Naive Bayes'),\n",
        "        ('bow', (1, 1), 'Bag of Words', 'svm', 'SVM (Linear)'),\n",
        "        ('bow', (1, 1), 'Bag of Words', 'lr', 'Logistic Regression'),\n",
        "        ('bow', (1, 1), 'Bag of Words', 'rf', 'Random Forest'),\n",
        "        ('tfidf', (1, 1), 'TF-IDF (1-gram)', 'nb', 'Naive Bayes'),\n",
        "        ('tfidf', (1, 1), 'TF-IDF (1-gram)', 'svm', 'SVM (Linear)'),\n",
        "        ('tfidf', (1, 1), 'TF-IDF (1-gram)', 'lr', 'Logistic Regression'),\n",
        "        ('tfidf', (1, 1), 'TF-IDF (1-gram)', 'rf', 'Random Forest'),\n",
        "        ('tfidf', (1, 2), 'TF-IDF (1-2-gram)', 'nb', 'Naive Bayes'),\n",
        "        ('tfidf', (1, 2), 'TF-IDF (1-2-gram)', 'svm', 'SVM (Linear)'),\n",
        "        ('tfidf', (1, 2), 'TF-IDF (1-2-gram)', 'lr', 'Logistic Regression'),\n",
        "        ('tfidf', (1, 2), 'TF-IDF (1-2-gram)', 'rf', 'Random Forest'),\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "    best_vectorizer = None\n",
        "    best_config = None\n",
        "\n",
        "    print(\"\\nRunning 12 experiments...\\n\")\n",
        "\n",
        "    for feat_type, ngram, feat_name, model_type, model_name in configs:\n",
        "        print(f\"Training: {model_name} + {feat_name}\")\n",
        "\n",
        "        # Create vectorizer\n",
        "        if feat_type == 'bow':\n",
        "            vectorizer = CountVectorizer(\n",
        "                max_features=5000,\n",
        "                ngram_range=ngram,\n",
        "                stop_words='english'\n",
        "            )\n",
        "        else:\n",
        "            vectorizer = TfidfVectorizer(\n",
        "                max_features=5000,\n",
        "                ngram_range=ngram,\n",
        "                stop_words='english'\n",
        "            )\n",
        "\n",
        "        # Vectorize\n",
        "        X_train_vec = vectorizer.fit_transform(X_train)\n",
        "        X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "        # Create model\n",
        "        if model_type == 'nb':\n",
        "            model = MultinomialNB()\n",
        "        elif model_type == 'svm':\n",
        "            model = LinearSVC(random_state=42, max_iter=2000)\n",
        "        elif model_type == 'lr':\n",
        "            model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "        else:\n",
        "            model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "        # Train\n",
        "        model.fit(X_train_vec, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, average='weighted')\n",
        "        rec = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        # Cross-validation\n",
        "        cv_scores = cross_val_score(model, X_train_vec, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "        results.append({\n",
        "            'Feature': feat_name,\n",
        "            'Model': model_name,\n",
        "            'Accuracy': acc,\n",
        "            'Precision': prec,\n",
        "            'Recall': rec,\n",
        "            'F1-Score': f1,\n",
        "            'CV Mean': cv_scores.mean(),\n",
        "            'CV Std': cv_scores.std()\n",
        "        })\n",
        "\n",
        "        print(f\"  Acc: {acc:.3f} | F1: {f1:.3f} | CV: {cv_scores.mean():.3f}\")\n",
        "\n",
        "        # Track best model\n",
        "        if f1 > best_score:\n",
        "            best_score = f1\n",
        "            best_model = model\n",
        "            best_vectorizer = vectorizer\n",
        "            best_config = (feat_name, model_name)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RESULTS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv('results/experiment_results.csv', index=False)\n",
        "    print(\"\\n Saved results to: results/experiment_results.csv\")\n",
        "\n",
        "    print(f\"\\n BEST MODEL: {best_config[1]} + {best_config[0]}\")\n",
        "    print(f\"   F1-Score: {best_score:.4f}\")\n",
        "\n",
        "    return results_df, best_model, best_vectorizer, best_config\n",
        "\n",
        "\n",
        "# STEP 5: VISUALIZE RESULTS\n",
        "\n",
        "\n",
        "def visualize_results(results_df):\n",
        "    \"\"\"Create visualizations of results\"\"\"\n",
        "    print(\"\\n[5/7] CREATING VISUALIZATIONS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Bar plot\n",
        "    pivot = results_df.pivot(index='Model', columns='Feature', values='Accuracy')\n",
        "    pivot.plot(kind='bar', ax=axes[0], rot=45)\n",
        "    axes[0].set_title('Accuracy Comparison', fontweight='bold', fontsize=14)\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].legend(title='Feature Type', bbox_to_anchor=(1.05, 1))\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Heatmap\n",
        "    pivot_f1 = results_df.pivot(index='Model', columns='Feature', values='F1-Score')\n",
        "    sns.heatmap(pivot_f1, annot=True, fmt='.3f', cmap='YlGnBu', ax=axes[1],\n",
        "                cbar_kws={'label': 'F1-Score'})\n",
        "    axes[1].set_title('F1-Score Heatmap', fontweight='bold', fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    print(\" Saved visualization: results/model_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# STEP 6: BEST MODEL ANALYSIS\n",
        "\n",
        "\n",
        "def analyze_best_model(best_model, best_vectorizer, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Detailed analysis of best model\"\"\"\n",
        "    print(\"\\n[6/7] BEST MODEL ANALYSIS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Transform data\n",
        "    X_train_vec = best_vectorizer.transform(X_train)\n",
        "    X_test_vec = best_vectorizer.transform(X_test)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = best_model.predict(X_test_vec)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Politics (0)', 'Sports (1)'],\n",
        "                yticklabels=['Politics (0)', 'Sports (1)'])\n",
        "    plt.title('Confusion Matrix - Best Model', fontweight='bold', fontsize=14)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    print(\" Saved visualization: results/confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\n Classification Report:\")\n",
        "    print(\"-\" * 80)\n",
        "    target_names = ['Politics (0)', 'Sports (1)']\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "# STEP 7: SAVE MODEL AND TEST\n",
        "\n",
        "\n",
        "def save_and_test_model(best_model, best_vectorizer):\n",
        "    \"\"\"Save model and test with new examples\"\"\"\n",
        "    print(\"\\n[7/7] SAVING MODEL & TESTING\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Save model\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "\n",
        "    model_data = {\n",
        "        'model': best_model,\n",
        "        'vectorizer': best_vectorizer\n",
        "    }\n",
        "\n",
        "    with open('models/best_classifier.pkl', 'wb') as f:\n",
        "        pickle.dump(model_data, f)\n",
        "\n",
        "    print(\" Model saved to: models/best_classifier.pkl\")\n",
        "\n",
        "    # Test with new examples\n",
        "    test_examples = [\n",
        "        \"The basketball team won the championship in overtime with a buzzer beater\",\n",
        "        \"Senate voted on the healthcare reform bill after lengthy debate\",\n",
        "        \"Olympic swimmer breaks world record in 200m freestyle finals\",\n",
        "        \"President signs executive order addressing climate change policy\",\n",
        "        \"Football striker scores hat-trick in crucial derby match victory\",\n",
        "        \"Congressional committee investigates corruption allegations in government\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n Testing with new examples:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    X_new = best_vectorizer.transform(test_examples)\n",
        "    predictions = best_model.predict(X_new)\n",
        "\n",
        "    # Get probabilities if available\n",
        "    if hasattr(best_model, 'predict_proba'):\n",
        "        probas = best_model.predict_proba(X_new)\n",
        "    elif hasattr(best_model, 'decision_function'):\n",
        "        decision = best_model.decision_function(X_new)\n",
        "        probas = np.exp(decision) / (1 + np.exp(decision))\n",
        "        probas = np.column_stack([1 - probas, probas])\n",
        "    else:\n",
        "        probas = None\n",
        "\n",
        "    for i, (text, pred) in enumerate(zip(test_examples, predictions)):\n",
        "        label_name = \"Sports\" if pred == 1 else \"Politics\"\n",
        "\n",
        "        if probas is not None:\n",
        "            confidence = probas[i][pred] * 100\n",
        "            print(f\"\\n{i+1}. {text}\")\n",
        "            print(f\"   → Label: {pred} ({label_name}) | Confidence: {confidence:.1f}%\")\n",
        "        else:\n",
        "            print(f\"\\n{i+1}. {text}\")\n",
        "            print(f\"   → Label: {pred} ({label_name})\")\n",
        "\n",
        "\n",
        "# MAIN EXECUTION\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # Load data\n",
        "    df = load_data_from_files()\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(\"\\n ERROR: No data loaded. Please check your files:\")\n",
        "        print(\"   - data/sports.txt\")\n",
        "        print(\"   - data/politics.txt\")\n",
        "        return\n",
        "\n",
        "    # EDA\n",
        "    df = perform_eda(df)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = prepare_train_test_split(df)\n",
        "\n",
        "    # Train models\n",
        "    results_df, best_model, best_vectorizer, best_config = train_all_models(\n",
        "        X_train, X_test, y_train, y_test\n",
        "    )\n",
        "\n",
        "    # Visualize\n",
        "    visualize_results(results_df)\n",
        "\n",
        "    # Analyze best model\n",
        "    y_pred = analyze_best_model(best_model, best_vectorizer,\n",
        "                                 X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Save and test\n",
        "    save_and_test_model(best_model, best_vectorizer)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" CLASSIFICATION COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(\"   results/eda_analysis.png - Data exploration\")\n",
        "    print(\"   results/model_comparison.png - Model performance\")\n",
        "    print(\"   results/confusion_matrix.png - Best model accuracy\")\n",
        "    print(\"   results/experiment_results.csv - Detailed results\")\n",
        "    print(\"   models/best_classifier.pkl - Trained model\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWEyORt1yARU",
        "outputId": "8010c4c5-a88b-433e-ea99-16d501891bd1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SPORTS VS POLITICS TEXT CLASSIFIER\n",
            "Label Convention: 1 = Sports, 0 = Politics\n",
            "================================================================================\n",
            "\n",
            "[1/7] LOADING DATA FROM FILES\n",
            "--------------------------------------------------------------------------------\n",
            " Loaded sports data from data/sports.txt\n",
            " Loaded politics data from data/politics.txt\n",
            "\n",
            " Dataset Summary:\n",
            "   Total documents: 60\n",
            "   Sports (label=1): 30\n",
            "   Politics (label=0): 30\n",
            "\n",
            "[2/7] EXPLORATORY DATA ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " Text Statistics by Category:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sports (label=1):\n",
            "  Count: 30\n",
            "  Avg length: 86.9 characters\n",
            "  Avg words: 12.0 words\n",
            "  Min words: 10\n",
            "  Max words: 14\n",
            "\n",
            "Politics (label=0):\n",
            "  Count: 30\n",
            "  Avg length: 89.0 characters\n",
            "  Avg words: 10.9 words\n",
            "  Min words: 9\n",
            "  Max words: 13\n",
            "\n",
            "✓ Saved visualization: results/eda_analysis.png\n",
            "\n",
            " Top Words by Category:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sports (label=1):\n",
            "  team................    9\n",
            "  record..............    7\n",
            "  championship........    6\n",
            "  victory.............    6\n",
            "  match...............    5\n",
            "  final...............    5\n",
            "  game................    4\n",
            "  wins................    4\n",
            "  champion............    4\n",
            "  tournament..........    4\n",
            "\n",
            "Politics (label=0):\n",
            "  political...........    6\n",
            "  international.......    4\n",
            "  government..........    4\n",
            "  bill................    4\n",
            "  state...............    4\n",
            "  announces...........    4\n",
            "  committee...........    3\n",
            "  legislation.........    3\n",
            "  party...............    3\n",
            "  rights..............    3\n",
            "\n",
            "[3/7] PREPARING TRAIN-TEST SPLIT\n",
            "--------------------------------------------------------------------------------\n",
            "Training set: 48 documents\n",
            "  Sports (1): 24\n",
            "  Politics (0): 24\n",
            "\n",
            "Test set: 12 documents\n",
            "  Sports (1): 6\n",
            "  Politics (0): 6\n",
            "\n",
            "[4/7] TRAINING MULTIPLE MODELS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Running 12 experiments...\n",
            "\n",
            "Training: Naive Bayes + Bag of Words\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 1.000\n",
            "Training: SVM (Linear) + Bag of Words\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 1.000\n",
            "Training: Logistic Regression + Bag of Words\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 0.980\n",
            "Training: Random Forest + Bag of Words\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 0.918\n",
            "Training: Naive Bayes + TF-IDF (1-gram)\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 1.000\n",
            "Training: SVM (Linear) + TF-IDF (1-gram)\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 1.000\n",
            "Training: Logistic Regression + TF-IDF (1-gram)\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 1.000\n",
            "Training: Random Forest + TF-IDF (1-gram)\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 0.958\n",
            "Training: Naive Bayes + TF-IDF (1-2-gram)\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 1.000\n",
            "Training: SVM (Linear) + TF-IDF (1-2-gram)\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 1.000\n",
            "Training: Logistic Regression + TF-IDF (1-2-gram)\n",
            "  Acc: 1.000 | F1: 1.000 | CV: 0.933\n",
            "Training: Random Forest + TF-IDF (1-2-gram)\n",
            "  Acc: 0.917 | F1: 0.916 | CV: 0.836\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "          Feature               Model  Accuracy  Precision   Recall  F1-Score  CV Mean   CV Std\n",
            "     Bag of Words         Naive Bayes  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000\n",
            "     Bag of Words        SVM (Linear)  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000\n",
            "     Bag of Words Logistic Regression  1.000000   1.000000 1.000000  1.000000 0.980000 0.040000\n",
            "     Bag of Words       Random Forest  1.000000   1.000000 1.000000  1.000000 0.917778 0.117084\n",
            "  TF-IDF (1-gram)         Naive Bayes  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000\n",
            "  TF-IDF (1-gram)        SVM (Linear)  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000\n",
            "  TF-IDF (1-gram) Logistic Regression  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000\n",
            "  TF-IDF (1-gram)       Random Forest  1.000000   1.000000 1.000000  1.000000 0.957778 0.051831\n",
            "TF-IDF (1-2-gram)         Naive Bayes  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000\n",
            "TF-IDF (1-2-gram)        SVM (Linear)  1.000000   1.000000 1.000000  1.000000 1.000000 0.000000\n",
            "TF-IDF (1-2-gram) Logistic Regression  1.000000   1.000000 1.000000  1.000000 0.933333 0.133333\n",
            "TF-IDF (1-2-gram)       Random Forest  0.916667   0.928571 0.916667  0.916084 0.835556 0.137239\n",
            "\n",
            " Saved results to: results/experiment_results.csv\n",
            "\n",
            " BEST MODEL: Naive Bayes + Bag of Words\n",
            "   F1-Score: 1.0000\n",
            "\n",
            "[5/7] CREATING VISUALIZATIONS\n",
            "--------------------------------------------------------------------------------\n",
            " Saved visualization: results/model_comparison.png\n",
            "\n",
            "[6/7] BEST MODEL ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            " Saved visualization: results/confusion_matrix.png\n",
            "\n",
            " Classification Report:\n",
            "--------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Politics (0)       1.00      1.00      1.00         6\n",
            "  Sports (1)       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n",
            "\n",
            "[7/7] SAVING MODEL & TESTING\n",
            "--------------------------------------------------------------------------------\n",
            " Model saved to: models/best_classifier.pkl\n",
            "\n",
            " Testing with new examples:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "1. The basketball team won the championship in overtime with a buzzer beater\n",
            "   → Label: 1 (Sports) | Confidence: 99.8%\n",
            "\n",
            "2. Senate voted on the healthcare reform bill after lengthy debate\n",
            "   → Label: 0 (Politics) | Confidence: 98.5%\n",
            "\n",
            "3. Olympic swimmer breaks world record in 200m freestyle finals\n",
            "   → Label: 1 (Sports) | Confidence: 99.6%\n",
            "\n",
            "4. President signs executive order addressing climate change policy\n",
            "   → Label: 0 (Politics) | Confidence: 99.9%\n",
            "\n",
            "5. Football striker scores hat-trick in crucial derby match victory\n",
            "   → Label: 1 (Sports) | Confidence: 99.8%\n",
            "\n",
            "6. Congressional committee investigates corruption allegations in government\n",
            "   → Label: 0 (Politics) | Confidence: 99.8%\n",
            "\n",
            "================================================================================\n",
            " CLASSIFICATION COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "Generated Files:\n",
            "   results/eda_analysis.png - Data exploration\n",
            "   results/model_comparison.png - Model performance\n",
            "   results/confusion_matrix.png - Best model accuracy\n",
            "   results/experiment_results.csv - Detailed results\n",
            "   models/best_classifier.pkl - Trained model\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Helper Script: Create Data Files from DataFrames\n",
        "Converts pandas DataFrames to the required text file format\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# USAGE EXAMPLES\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*80)\n",
        "    print(\"DATA FILE CREATOR\")\n",
        "    print(\"Creates sports.txt and politics.txt in correct format\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Example 1: Create sample files\n",
        "    print(\"\\n Creating sample data files...\\n\")\n",
        "    sports_df, politics_df = create_sample_data_files()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\" DONE! You can now run:\")\n",
        "    print(\"   python classifier_with_labels.py\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Example 2: If you already have DataFrames\n",
        "    \"\"\"\n",
        "    # Uncomment and use this if you have your own DataFrames:\n",
        "\n",
        "    # Load your data\n",
        "    sports_df = pd.read_csv('your_sports_data.csv')  # Must have 'content' column\n",
        "    politics_df = pd.read_csv('your_politics_data.csv')  # Must have 'content' column\n",
        "\n",
        "    # Create files\n",
        "    create_data_files_from_dataframes(sports_df, politics_df)\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEYJ4IKMyDU1",
        "outputId": "ed5cc3c4-71a2-40f3-d15c-93b210f86c9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATA FILE CREATOR\n",
            "Creates sports.txt and politics.txt in correct format\n",
            "================================================================================\n",
            "\n",
            " Creating sample data files...\n",
            "\n",
            "✓ Created data/sports.txt with 30 articles\n",
            "✓ Created data/politics.txt with 30 articles\n",
            "\n",
            " Files created successfully in 'data/' directory\n",
            "\n",
            "================================================================================\n",
            " DONE! You can now run:\n",
            "   python classifier_with_labels.py\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}